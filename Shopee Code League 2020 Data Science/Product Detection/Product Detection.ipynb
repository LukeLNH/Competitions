{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Notebook is for Shoppee's Product Detection Competition. All Datasets belong to Shoppee and can be found "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePreprocessor(BaseEstimator, TransformerMixin):\n",
    "    # the 3 methods that need to be implemented when inheriting from BaseEstimator and TransformerMixin\n",
    "    def __init__(self, img_size):\n",
    "        self._img_size = img_size\n",
    "        \n",
    "    def fit(self, X, y = None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y = None):\n",
    "        if y is not None:\n",
    "            return np.array(list(map(self.preprocess_image, X))), self.one_hot_encode(y)\n",
    "        else:\n",
    "            return np.array(list(map(self.preprocess_image, X)))\n",
    "        \n",
    "    \n",
    "    def preprocess_image(self, image):\n",
    "        image = tf.image.resize(image, (self._img_size, self._img_size))\n",
    "        image = cv2.cvtColor(np.float32(image), cv2.COLOR_BGR2RGB) #converting color back properly because cv2 reads the image in BGR colors\n",
    "        image = cv2.GaussianBlur(image, (5,5),0) #denoise the image\n",
    "        #resize image\n",
    "        #grayscale image: Will not grayscale because using MobileNetV2\n",
    "        image = (image/255 - 0.5)\n",
    "        #perform gridmask on images:\n",
    "        \n",
    "        return image\n",
    "    \n",
    "    def one_hot_encode(self, y):\n",
    "        y = np.array(y)\n",
    "        y_post = np.zeros(y.shape[0] * 42).reshape(y.shape[0], 42)\n",
    "        for index in range(y.shape[0]):\n",
    "            y_post[index, y[index]] = 1\n",
    "        del y\n",
    "        gc.collect()\n",
    "        return y_post"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SIZE = 96\n",
    "preprocessor = ImagePreprocessor(IMG_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_names(string):\n",
    "    return string[15:]\n",
    "\n",
    "\n",
    "class Pipeline():\n",
    "    def __init__(self, preprocessor, model):\n",
    "        self._preprocessor = preprocessor\n",
    "        self._model = model\n",
    "    \n",
    "    def fit(self, X_train, X_test, y_train, y_test, batch_size = 200, epochs = 5):\n",
    "        print('preprocessing...')\n",
    "        X_train, y_train = self._preprocessor.transform(X_train, y_train)\n",
    "        X_test, y_test = self._preprocessor.transform(X_test, y_test)\n",
    "\n",
    "        print('training...')\n",
    "        self._model.fit(X_train, y_train,\n",
    "                 batch_size = batch_size,\n",
    "                 epochs = epochs,\n",
    "                 validtion_set = [(X_train, y_train), (X_test, y_test)])\n",
    "        \n",
    "    def predict(self, X_pred):\n",
    "        X_pred = self._preprocessor.transform(X_pred)\n",
    "        return np.argmax(model.predict(X_pred), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # filenames = glob.glob(\"train/train/00/*.jpg\")\n",
    "# filenames = []\n",
    "# for n in range(42):\n",
    "#     train_file = \"\"\n",
    "#     if n < 10:\n",
    "#         train_file = \"0\" + str(n)\n",
    "#     else:\n",
    "#         train_file = str(n)\n",
    "    \n",
    "#     filepath = 'train/train/' + train_file + '/*.jpg'\n",
    "#     filenames += glob.glob(filepath)\n",
    "    \n",
    "# #shuffle 10 times:\n",
    "# for z in range(10):\n",
    "#     np.random.shuffle(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filenames = glob.glob(\"train/train/00/*.jpg\")\n",
    "filenames = []\n",
    "for n in range(42):\n",
    "    train_file = \"\"\n",
    "    if n < 10:\n",
    "        train_file = \"0\" + str(n)\n",
    "    else:\n",
    "        train_file = str(n)\n",
    "    \n",
    "    filepath = 'train/train/' + train_file + '/*.jpg'\n",
    "    all_files = np.array(glob.glob(filepath))\n",
    "    np.random.shuffle(all_files)\n",
    "    all_files = all_files.tolist()[:240]\n",
    "    filenames +=  all_files\n",
    "    \n",
    "#shuffle 10 times:\n",
    "for z in range(10):\n",
    "    np.random.shuffle(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n",
    "UNTRAINABLE_BEFORE_LAYER = 50\n",
    "\n",
    "#Google's MobileNetV2 model\n",
    "#base_model  = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE, include_top = False)\n",
    "\n",
    "#Facebook's ResNet152V2 model\n",
    "base_model = tf.keras.applications.ResNet101V2(input_shape=IMG_SHAPE, include_top=False)\n",
    "\n",
    "base_model.trainable = True\n",
    "for layer in base_model.layers[: UNTRAINABLE_BEFORE_LAYER]:\n",
    "    layer.trainable = False\n",
    "    \n",
    "model = keras.Sequential([\n",
    "    base_model,\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(42, activation=\"sigmoid\")\n",
    "])\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(learning_rate=0.0001, decay = 1e-6),\n",
    "              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(preprocessor, model)\n",
    "sample_size = 1000\n",
    "def main(): \n",
    "    for r in range(4):\n",
    "        print(\"round: \" + str(r+1) + \"/4\")\n",
    "        n = 0\n",
    "        while n + sample_size < len(filenames):\n",
    "            print(str(n + sample_size) + ' samples')\n",
    "            temp = filenames[n : n + sample_size]\n",
    "            shortened_names = list(map(sort_names, temp))\n",
    "            X_train = list(map(cv2.imread, temp[:int(sample_size * 0.9)]))\n",
    "            X_test = list(map(cv2.imread, temp[int(sample_size * 0.9):]))\n",
    "\n",
    "\n",
    "            y_train = df[df[\"filename\"].isin(shortened_names[:int(sample_size * 0.9)])]\n",
    "            y_train[\"order\"] = pd.Categorical(y_train[\"filename\"],\n",
    "                                              categories=shortened_names[:int(sample_size * 0.9)],\n",
    "                                              ordered = True)\n",
    "            y_train.sort_values(\"order\", inplace = True)\n",
    "            y_train.drop(columns = [\"filename\", \"order\"], inplace = True)\n",
    "\n",
    "\n",
    "            y_test = df[df[\"filename\"].isin(shortened_names[int(sample_size * 0.9):])]\n",
    "            y_test[\"order\"] = pd.Categorical(y_test[\"filename\"],\n",
    "                                             categories=shortened_names[int(sample_size * 0.9):],\n",
    "                                             ordered = True)\n",
    "            y_test.sort_values(\"order\", inplace = True)\n",
    "            y_test.drop(columns = [\"filename\", \"order\"], inplace = True)\n",
    "\n",
    "\n",
    "            del temp, shortened_names\n",
    "            gc.collect()\n",
    "\n",
    "            pipeline.fit(X_train, X_test, y_train, y_test, batch_size=42, epochs = 1)\n",
    "\n",
    "            del X_train, X_test, y_train, y_test\n",
    "            gc.collect()\n",
    "            n += sample_size\n",
    "        \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_files = filenames[10000:]\n",
    "test_images = list(map(cv2.imread,test_files))\n",
    "test_files = list(map(sort_names, test_files))\n",
    "\n",
    "test_labels = df[df[\"filename\"].isin(test_files)]\n",
    "test_labels[\"order\"] = pd.Categorical(test_labels[\"filename\"], categories=test_files, ordered = True)\n",
    "test_labels.sort_values(\"order\", inplace = True)\n",
    "test_labels.drop(columns = [\"filename\", \"order\"], inplace = True)\n",
    "test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images = preprocessor.transform(test_images)\n",
    "predictions = np.argmax(model.predict(test_images), axis = 1)\n",
    "test_labels = test_labels.reshape(test_labels.shape[0],)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(predictions == test_labels).sum()/test_labels.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_labels = df[df[\"filename\"].isin(test_files)]\n",
    "# test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_labels[\"order\"] = pd.Categorical(\n",
    "#     test_labels[\"filename\"],\n",
    "#     categories = test_files,\n",
    "#     ordered = True\n",
    "# )\n",
    "# test_labels.sort_values(\"order\", inplace = True)\n",
    "# test_labels.drop(columns=[\"filename\", \"order\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_path = \"test/test/*.jpg\"\n",
    "pred_df = pd.read_csv(\"test.csv\")\n",
    "pred_image_files = glob.glob(pred_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_images = list(map(lambda string : string[10:], pred_image_files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[\"order\"] = pd.Categorical(pred_df[\"filename\"], categories=pred_images, ordered=True)\n",
    "pred_df.sort_values(\"order\", inplace=True)\n",
    "pred_df.drop(columns=[\"category\", \"order\"], inplace=True)\n",
    "pred_df.reset_index(drop = True, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for file in pred_images:\n",
    "    if file not in np.array(pred_df[\"filename\"]):\n",
    "        pred_images.remove(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = np.array([])\n",
    "count = 0\n",
    "for file in pred_images:\n",
    "    print(count)\n",
    "    count+=1\n",
    "    image = [cv2.imread(\"test/test\\\\\" + file)]\n",
    "    prediction = pipeline.predict(image)\n",
    "    category = np.concatenate((category, prediction), axis = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df[\"category\"] = pd.Series(category)\n",
    "pred_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df.to_csv(\"submission1.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
